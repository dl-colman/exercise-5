{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis of Twitter Data\n",
        "\n",
        "<img src=\"https://hub.packtpub.com/wp-content/uploads/2018/03/Sentiment-Analysis-Tw.png\">"
      ],
      "metadata": {
        "id": "0Yw6IW0ldPOu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1BCsrYhRGFe"
      },
      "source": [
        "# Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO1nqFwBRQ9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4a3843-9541-409c-8f01-18972e6cc66f"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlGPqUXER9th"
      },
      "source": [
        "# Stage 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HjlRC0lSC9H"
      },
      "source": [
        "## Downloading Data\n",
        "The data we gonna use in this exercise is hand­curated twitter sentiment dataset published by Sander’s Lab. It contains tweets from 2007­-2011 that mention one of four major Tech companies. Sander’s Lab manually assigned labels for each tweet as either “Positive”, “Negative”, “Neutral”, or “Irrelevant”.<br>\n",
        "\n",
        "“Positive” and “Negative” indicated whether or not the tweet showed a generally favorable or\n",
        "unfavorable opinion toward the mentioned company. A “Neutral” labelling indicated that the tweet\n",
        "was either purely informative or the opinion of the tweet was otherwise ambiguous. <br>An “Irrelevant” labelling indicated that the tweet could not be determined to fit into any of the other\n",
        "classes. <br>This often indicated that the tweet was not written in english or that it was clearly spam.\n",
        "\n",
        "[You can read more about the data in the following link:](http://cs229.stanford.edu/proj2013/TatumSanchez-TwitterSentimentAnalysis.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnkY4PseR1gk"
      },
      "source": [
        "%%capture\n",
        "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
        "!unzip trainingandtestdata.zip"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read train and test sets with Pandas"
      ],
      "metadata": {
        "id": "GRM7nH3yyvvx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqWJJivxSJfZ"
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "train_data = pd.read_csv(\n",
        "    \"/content/training.1600000.processed.noemoticon.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")\n",
        "test_data = pd.read_csv(\n",
        "   \"/content/testdata.manual.2009.06.14.csv\",\n",
        "   header=None,\n",
        "   names=cols,\n",
        "   engine=\"python\",\n",
        "   encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "1CaW09dvTNRl",
        "outputId": "e836a51d-2f2e-40b4-9a41-a8b83967222f"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment          id                          date     query  \\\n",
              "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f97568c9-348e-4511-af92-a469c5581ec7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f97568c9-348e-4511-af92-a469c5581ec7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f97568c9-348e-4511-af92-a469c5581ec7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f97568c9-348e-4511-af92-a469c5581ec7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZzk6FhvUAhL"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgz1vFdDUg6K"
      },
      "source": [
        "data = train_data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt6o07ZhUAqX"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR-coRzaUWKl"
      },
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
        "          axis=1,\n",
        "          inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "Gqfuw0UE2vqv",
        "outputId": "d7caed04-dfae-4b0b-d28a-731c8e9f1867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1600000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function - clean single tweet\n",
        "\n",
        "\n",
        "*   Use BeautifulSoup tools to deal with different formats of the text (lxml). And it retuen a single (text) format.\n",
        "*   Use regex to get rid of unwanted subexpressions.\n",
        "\n"
      ],
      "metadata": {
        "id": "cvpWyi3izFcd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdvNeoqGUpQU"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhsUjyKGUpjM"
      },
      "source": [
        "data_clean = data.text.apply(clean_tweet)  # take about 7 mins"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aUx1D44tA1c",
        "outputId": "db206fbc-0684-43ca-a8db-d083246dd1e8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Awww that's a bummer. You shoulda got David C...\n",
              "1    is upset that he can't update his Facebook by ...\n",
              "2     I dived many times for the ball. Managed to s...\n",
              "3      my whole body feels itchy and like its on fire \n",
              "4     no it's not behaving at all. i'm mad. why am ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data labeling"
      ],
      "metadata": {
        "id": "hXYAqZeM1cu2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmCXE6dcUqNG"
      },
      "source": [
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBslUHA8UqVG",
        "outputId": "9cfc068d-e517-4dd1-858b-9d43853f4642"
      },
      "source": [
        "set(data_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa5A32xEUAsp"
      },
      "source": [
        "### Tokenization\n",
        "In this part we will create the Tokenizer Encoder.<br>\n",
        "target_vocab_size=2**16 = ~64,000 - The number of all words in the English language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPqjqi3XVyB1"
      },
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    data_clean, target_vocab_size=2**16 \n",
        ")  # takes about 8 - 9 mins"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode the tokens"
      ],
      "metadata": {
        "id": "G8I3zbFt4yRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_inputs = data_clean.apply(tokenizer.encode) # takes about 6 mins"
      ],
      "metadata": {
        "id": "n0znEo2UDR7M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_inputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANogqglVme_b",
        "outputId": "c39ac6b0-fb62-41bc-d919-52b9d4186128"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[65316, 1570, 113, 65323, 10, 6, 3553, 1, 135, 5262, 50, 1484, 38165, 16, 13337, 606, 2, 49, 33, 1, 65352]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmFvqTCsUAuu"
      },
      "source": [
        "### Padding\n",
        "We want all sentences to be the same length. Therefore, we will consider the longest sentence and define it as the desired length for all sentences. For every other sentence that is shorter than the longest sentence, we will pad the empty spaces with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoEGVYv3WDuu"
      },
      "source": [
        "MAX_LEN = max([len(sentence) for sentence in data_inputs])\n",
        "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n",
        "                                                            value=0,\n",
        "                                                            padding=\"post\",\n",
        "                                                            maxlen=MAX_LEN)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_inputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-sffTbgtZR2",
        "outputId": "ea4231f7-4492-4f80-f178-82061fc3da77"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[65316  1570   113 65323    10     6  3553     1   135  5262    50  1484\n",
            " 38165    16 13337   606     2    49    33     1 65352     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akk6Q5UAUAxF"
      },
      "source": [
        "### Spliting into training/testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHyNPPZeUPIM"
      },
      "source": [
        "test_idx = np.random.randint(0, 800000, 8000)\n",
        "test_idx = np.concatenate((test_idx, test_idx+800000))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0IUjukjWrfL"
      },
      "source": [
        "test_inputs = data_inputs[test_idx]\n",
        "test_labels = data_labels[test_idx]\n",
        "train_inputs = np.delete(data_inputs, test_idx, axis=0)\n",
        "train_labels = np.delete(data_labels, test_idx)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM1XK5DSvTHN",
        "outputId": "459d2ba8-c722-4a88-9282-042edc1d7ded"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 73)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18cFC9RJvcuW",
        "outputId": "75b272c7-3d38-4d72-a8d9-9353b2f2df04"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1584100, 73)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcawn1QQW-IF"
      },
      "source": [
        "# Stage 3: Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://i.stack.imgur.com/YREV2.png' width=50% hight=50%/>\n",
        "<figcaption>Model Architecture</figcaption></center>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "5nMgCNSLbs9i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIxMpgtIW_rG"
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 emb_dim=128,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"dcnn\"):\n",
        "        super(DCNN, self).__init__(name=name)\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size,\n",
        "                                          emb_dim)\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.pool_1 = layers.GlobalMaxPool1D()\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.pool_2 = layers.GlobalMaxPool1D()\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool_3 = layers.GlobalMaxPool1D()\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "        x_1 = self.bigram(x)\n",
        "        x_1 = self.pool_1(x_1)\n",
        "        x_2 = self.trigram(x)\n",
        "        x_2 = self.pool_2(x_2)\n",
        "        x_3 = self.fourgram(x)\n",
        "        x_3 = self.pool_3(x_3)\n",
        "\n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # shape = (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz6mIdctaFjE"
      },
      "source": [
        "# Stage 4: Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM_VB88IaH39"
      },
      "source": [
        "## Config\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARyYLOSwaHNB"
      },
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = len(set(train_labels))\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsR2YTR3aXvt"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5dx9_XKaYvn"
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
        "            emb_dim=EMB_DIM,\n",
        "            nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvaps3Z8aqS3"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save checkpoints during training\n",
        "You can use a trained model without having to retrain it, or pick-up training where you left off in case the training process was interrupted. The `tf.train.CheckpointManager` callback allows you to continually save the model both *during* and at *the end* of training."
      ],
      "metadata": {
        "id": "qQ3El_5mnrxD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pikLkK-ua9ke"
      },
      "source": [
        "checkpoint_path = \"ckpt/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC6rplJkbVfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "07428d87-9298-47f0-93b8-12ca7d991a1a"
      },
      "source": [
        "Dcnn.fit(train_inputs,\n",
        "         train_labels,\n",
        "         batch_size=BATCH_SIZE,\n",
        "         epochs=NB_EPOCHS)     # 1 epoch = 15 to 18 mins\n",
        "ckpt_manager.save()  "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "49503/49503 [==============================] - 280s 5ms/step - loss: 0.3987 - accuracy: 0.8200\n",
            "Epoch 2/5\n",
            "49503/49503 [==============================] - 269s 5ms/step - loss: 0.3334 - accuracy: 0.8571\n",
            "Epoch 3/5\n",
            "49503/49503 [==============================] - 271s 5ms/step - loss: 0.2812 - accuracy: 0.8835\n",
            "Epoch 4/5\n",
            "49503/49503 [==============================] - 269s 5ms/step - loss: 0.2288 - accuracy: 0.9079\n",
            "Epoch 5/5\n",
            "49503/49503 [==============================] - 273s 6ms/step - loss: 0.1841 - accuracy: 0.9274\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ckpt/ckpt-1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv3pbv1cbopL"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SykW2nwtbrAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d555258a-bffc-4dba-9474-714e685567fe"
      },
      "source": [
        "results = Dcnn.evaluate(test_inputs, test_labels, batch_size=BATCH_SIZE)\n",
        "print(results)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.8242\n",
            "[0.5150845050811768, 0.8241875171661377]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making a single prediction"
      ],
      "metadata": {
        "id": "YolMjufi-Lpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_single_prediction(given_text):\n",
        "  token_and_encode = [tokenizer.encode(given_text)]\n",
        "  result = Dcnn(np.array(token_and_encode), training=False).numpy()\n",
        "\n",
        "  if (result[0][0] > 0.5) == 1:\n",
        "    prediction = f'Positive (-:\\nprobability of {result[0][0]}'\n",
        "  else:\n",
        "    prediction = f'Negative )-:\\nprobability of {result[0][0]}'\n",
        "  print(prediction)"
      ],
      "metadata": {
        "id": "ECVhR0FX-Pk-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's try the trained model"
      ],
      "metadata": {
        "id": "Wf5dvcM1cLNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_single_prediction(\"i love deep learning very much\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuryhvjQ_chl",
        "outputId": "cc3bc013-2427-4f40-ad30-2a08961d5ef2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive (-:\n",
            "probability of 0.9955477714538574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_single_prediction(\"the sun will shine againe tomorrow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIkfwtGArhYO",
        "outputId": "787b15bb-3f7a-42cb-f1fe-b95d27b8a9a6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive (-:\n",
            "probability of 0.8977813720703125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_single_prediction(\"i wasn't expecting to have such a great time\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P4OerSsAhJf",
        "outputId": "17cded0a-12d4-4dde-d6f4-2042ef9e0c16"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive (-:\n",
            "probability of 0.7917581796646118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_single_prediction(\"i hate rainy days \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IU2KoDwA4eB",
        "outputId": "25228c1d-4463-4c54-ce3b-16b7bc41e93e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative )-:\n",
            "probability of 0.01484485063701868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_single_prediction(\"i wish i will have to do that again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAnAfzT9q-AU",
        "outputId": "16fb392d-13a4-4bcf-f73d-604a34eb3e67"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative )-:\n",
            "probability of 0.12742596864700317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_single_prediction(\"at the end of this course i have to defend my project\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isYnrRdIApzZ",
        "outputId": "8def0aa5-84b5-4e6f-ec9c-a2e5d69a9119"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative )-:\n",
            "probability of 0.09978639334440231\n"
          ]
        }
      ]
    }
  ]
}