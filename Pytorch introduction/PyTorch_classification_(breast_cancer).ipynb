{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Libraries for Neural Networks - PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "huMTTiZPbBm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs a specific PyTorch version"
      ],
      "metadata": {
        "id": "DuPCGIuUbZuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "BefKIa-GevKD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoOTnVFidwII"
      },
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch.nn as nn\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Loading the dataset\n",
        "The data set contains a table with 30 features for 569 subjects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iDc-CB-eGsY"
      },
      "source": [
        "breast = datasets.load_breast_cancer()\n",
        "breast.data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at what the data looks like"
      ],
      "metadata": {
        "id": "Ud9IaRPZca10"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DIAZpMdeOL-"
      },
      "source": [
        "breast.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how the header of the columns (the names of the features) looks like."
      ],
      "metadata": {
        "id": "A-0RVyencpZR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Paiw-uSgeUsF"
      },
      "source": [
        "breast.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this is how the labeling of the data can be displayed. As you can see the labeling is binary."
      ],
      "metadata": {
        "id": "hwvrodpBc4Ce"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU7L1plAelpi"
      },
      "source": [
        "breast.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the labeling: 0 - malignant (גידול ממאיר) and 1 - benign (גידול שפיר)."
      ],
      "metadata": {
        "id": "y8FJBazqeHMK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSirq1ogexpf"
      },
      "source": [
        "breast.target_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "3UuS2Ym1e6D3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_Qe8N8TtfFRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ],
      "metadata": {
        "id": "gCt3p0vwe-lJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split the data into features and labeling (X,y)"
      ],
      "metadata": {
        "id": "u-s6pMvMeV8t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2EfWdzMe1ml"
      },
      "source": [
        "X = breast.data\n",
        "y = breast.target"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will separate the training set from the test set"
      ],
      "metadata": {
        "id": "7UDXIgLPfJ2w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXAfgiLCfFLM"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_QBGhf8fa5W"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28tDG-Dwfg3C"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72uvlxJrOuWd"
      },
      "source": [
        "### Data transformation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we use Pytorch we will have to work with a different type of data structure and not a Numpy array"
      ],
      "metadata": {
        "id": "HOWzORT7fbT5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CDhI9lYfoSp"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, we will convert the data structure type to PyTorch Tensor"
      ],
      "metadata": {
        "id": "RKbyHcKdgh5N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j50JzYbvfxOB"
      },
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZpLPL9ZhGVv"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will use Tensor Dataset to connect the features and labeling and create a complete dataset. And now we can work with this data in PyTorch neural networks."
      ],
      "metadata": {
        "id": "UAEd025Jhk7G"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Yio0lMhJHC"
      },
      "source": [
        "dataset = torch.utils.data.TensorDataset(X_train, y_train)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbHuCVOLhS5u"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will use Data loader. It will combines a dataset and a sampler, and provides an iterable over the given dataset (also divides the data into batches(."
      ],
      "metadata": {
        "id": "6Qyvpczlh9Dy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEN5jCO-hZyT"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDLesyDQpIb"
      },
      "source": [
        "## Neural network structure\n",
        "30 -> 16 -> 16 -> 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8a5pCYviAHQ"
      },
      "source": [
        "network = nn.Sequential(nn.Linear(in_features=30, out_features=16),\n",
        "                        nn.Sigmoid(),\n",
        "                        nn.Linear(16, 16),\n",
        "                        nn.Sigmoid(),\n",
        "                        nn.Linear(16, 1),\n",
        "                        nn.Sigmoid())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network summary"
      ],
      "metadata": {
        "id": "GkQCJOzEid_t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3KO31Cbjrxb"
      },
      "source": [
        "network.parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create a Loss function (binary cross entropy) and optimizer"
      ],
      "metadata": {
        "id": "19M7GqJ4ikpm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi67gpD2jw2d"
      },
      "source": [
        "loss_function = nn.BCELoss()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5DwvzzpkCIS"
      },
      "source": [
        "optimizer = torch.optim.Adam(network.parameters(), lr = 0.001)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the neural network on the Training se"
      ],
      "metadata": {
        "id": "FIBpPg7ujBjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "avg_loss = 0\n",
        "loss_list, epochs_list = [], []"
      ],
      "metadata": {
        "id": "NJHIENQapcNt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn2TbtzfkP19"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  running_loss = 0.\n",
        "\n",
        "  for data in train_loader:\n",
        "    batch_features, batch_labels = data\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = network.forward(batch_features) \n",
        "    loss = loss_function(predictions, batch_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  if running_loss != 0:\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "  loss_list.append(avg_loss)\n",
        "  epochs_list.append(epoch)\n",
        "\n",
        "  print('Epoch: ' + str(epoch + 1) + ' loss: ' + str(avg_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Visualization\n"
      ],
      "metadata": {
        "id": "YuYh-0IJoQyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs_list,loss_list, label=\"Training Loss\")\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JOQvDY5yoTYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyTjLzELSdQF"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use `eval()` to set network's layers to evaluation mode before running inference.<br>\n",
        "If we wish to resuming training, we can call `network.train()` to set these layers to training mode."
      ],
      "metadata": {
        "id": "7b8Fu4slo4bY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lznvtd0vmyFu"
      },
      "source": [
        "network.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data transformation for the test set"
      ],
      "metadata": {
        "id": "LN4Sz14zqWeg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbfwUSOCnAqY"
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FX-fotsnEsW"
      },
      "source": [
        "X_test = torch.tensor(X_test, dtype=torch.float)\n",
        "type(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test model performance"
      ],
      "metadata": {
        "id": "qeL48glzqpGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the model returned us a list with probabilities"
      ],
      "metadata": {
        "id": "pNgTFM1TrBLd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEw01uzUnMYs"
      },
      "source": [
        "predictions = network.forward(X_test)\n",
        "predictions[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will replace the list of probabilities with a list of booleans. For the sake of this matter, we will use a threshold of 0.5"
      ],
      "metadata": {
        "id": "WiJqATNdrEfJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1ZtXPnnpiy"
      },
      "source": [
        "predictions = np.array(predictions > 0.5)\n",
        "predictions[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CENEXHlIoKni"
      },
      "source": [
        "y_test[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfjEpilWoSt8"
      },
      "source": [
        "accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HLl2Iy0oZ_p"
      },
      "source": [
        "cm = confusion_matrix(y_test, predictions)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfT3Ll9ofyi"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}